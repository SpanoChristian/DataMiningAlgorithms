{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Evaluation using Bootstrap\n",
    "Bootstrap can also be used to evaluate a classifier. Given the original data $D$, k datasets $D_i$ are generated from $D$ and used to train a model $M_i$ that is evaluated using the entire dataset $D$ returning the evaluation $\\theta_i$. The overall evaluation is computed as the mean and standard deviation of the $k$ values of $\\theta_i$. Note however that the estimates will be somewhat optimistic becvause of the overlap between the training (generated by bootstrap resampling) and the testing performed on the entire dataset (63.2%). Cross-validation does not suffer from this limitation since it keeps the training and testing sets disjoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "np.random.seed(238476293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y, ratio=1.0):\n",
    "    \n",
    "    # compute the number of rows of the generated dataset\n",
    "    n_rows = int(X.shape[0]*ratio)\n",
    "    \n",
    "    # compute the number of columns\n",
    "    n_cols = X.shape[1]\n",
    "    \n",
    "    # create the output dataset with all zero\n",
    "    sampled_X = np.zeros((n_rows,n_cols))\n",
    "    sampled_y = np.zeros(n_rows)\n",
    "        \n",
    "    # randomly select a row from the original dataset and then copy it to the output dataset\n",
    "    for s in range(n_rows):\n",
    "        sample_index = int(random.random()*n_rows)\n",
    "        sampled_X[s,:] = X[sample_index,:]\n",
    "        sampled_y[s] = y[sample_index]\n",
    "    \n",
    "    return sampled_X, sampled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_evaluation(classifier, X, y, k, metrics):\n",
    "    evaluation = []\n",
    "    for i in range(k):\n",
    "        bX,by = bootstrap(X,y)\n",
    "        classifier.fit(bX,by)        \n",
    "        yp = classifier.predict(X)\n",
    "        evaluation.append(metrics(y,yp))\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Data\n",
    "First, let apply bootstrap evaluation using a regression problem, the boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "evaluation = bootstrap_evaluation(LinearRegression(), X, y, 100, r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Evaluation 0.731 +/ 0.005\n"
     ]
    }
   ],
   "source": [
    "print(\"Bootstrap Evaluation %.3f +/ %.3f\"%(np.array(evaluation).mean(),np.array(evaluation).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "xval_evaluation = cross_val_score(LinearRegression(), X, y, cv=KFold(n_splits=10, random_state=1234, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation Evaluation 0.682 +/ 0.125\n"
     ]
    }
   ],
   "source": [
    "print(\"Crossvalidation Evaluation %.3f +/ %.3f\"%(np.array(xval_evaluation).mean(),np.array(xval_evaluation).std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Data\n",
    "Next, we can apply the same approach to a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Evaluation 0.971 +/ 0.010\n",
      "Crossvalidation Evaluation 0.967 +/ 0.045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "evaluation = bootstrap_evaluation(classifier, X, y, 100, accuracy_score)\n",
    "print(\"Bootstrap Evaluation %.3f +/ %.3f\"%(np.array(evaluation).mean(),np.array(evaluation).std()))\n",
    "\n",
    "xval_evaluation = cross_val_score(classifier, X, y, cv=KFold(n_splits=10, random_state=1234, shuffle=True))\n",
    "print(\"Crossvalidation Evaluation %.3f +/ %.3f\"%(np.array(xval_evaluation).mean(),np.array(xval_evaluation).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
