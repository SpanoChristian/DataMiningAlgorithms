{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Wrapper Approach using a Genetic Algorithm\n",
    "In this notebook we implement a rather simple feature selection procedure that follows a wrapper approach. The search algorithm, Genetic algorithms in this case, is wrapped around the target classification/regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deap in /Users/pierlucalanzi/opt/anaconda3/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in /Users/pierlucalanzi/opt/anaconda3/lib/python3.8/site-packages (from deap) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "# install the evolutionary computation library\n",
    "!pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "number_of_variables = X.shape[1]\n",
    "input_variables = data.feature_names\n",
    "target_variable = 'MEDV'\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# let's create also a pandas data frame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['MEDV'] = y\n",
    "df.head()\n",
    "\n",
    "kfolds = KFold(10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateFeatureSubsetSingleObjective(individual):\n",
    "    selected_columns = []\n",
    "    for i, allele in enumerate(individual):\n",
    "        if (allele==1):\n",
    "            selected_columns.append(df.columns[i])\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    scores = cross_val_score(model, df[selected_columns], y, cv=kfolds)\n",
    "    return scores.mean(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Genetic Algorithm\n",
    "If looks for the feature subset that maximizes the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "# creator.create(\"Individual\", list, typecode='b', fitness=creator.FitnessMax)\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, number_of_variables)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, number_of_variables)\n",
    "toolbox.register(\"evaluate\", EvaluateFeatureSubsetSingleObjective)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg   \tstd     \tmin     \tmax     \n",
      "0  \t100   \t0.5295\t0.111939\t0.230525\t0.673672\n",
      "1  \t58    \t0.608515\t0.0522335\t0.311601\t0.676593\n",
      "2  \t62    \t0.639771\t0.0246692\t0.560079\t0.679719\n",
      "3  \t76    \t0.655745\t0.0198035\t0.571319\t0.679957\n",
      "4  \t62    \t0.665384\t0.017312 \t0.585463\t0.683319\n",
      "5  \t62    \t0.673607\t0.0106756\t0.604827\t0.683319\n",
      "6  \t67    \t0.677223\t0.0106139\t0.596015\t0.686291\n",
      "7  \t47    \t0.68042 \t0.00520338\t0.641073\t0.686291\n",
      "8  \t62    \t0.681441\t0.00823372\t0.61548 \t0.686291\n",
      "9  \t55    \t0.682398\t0.00872825\t0.625077\t0.686291\n",
      "10 \t56    \t0.684159\t0.00669046\t0.644112\t0.686291\n",
      "11 \t66    \t0.684537\t0.00695231\t0.642208\t0.686291\n",
      "12 \t62    \t0.684968\t0.00670405\t0.642208\t0.686291\n",
      "13 \t65    \t0.685668\t0.00267743\t0.669372\t0.686291\n",
      "14 \t49    \t0.683982\t0.011128  \t0.610402\t0.686291\n",
      "15 \t56    \t0.683664\t0.0108812 \t0.601928\t0.686291\n",
      "16 \t69    \t0.681449\t0.0273114 \t0.43426 \t0.686291\n",
      "17 \t60    \t0.680364\t0.0289233 \t0.417941\t0.686291\n",
      "18 \t62    \t0.682277\t0.0154917 \t0.587232\t0.686291\n",
      "19 \t61    \t0.683507\t0.0128785 \t0.593238\t0.686291\n",
      "20 \t62    \t0.683664\t0.00998579\t0.627256\t0.686291\n",
      "21 \t57    \t0.682919\t0.0148898 \t0.579823\t0.686291\n",
      "22 \t63    \t0.683584\t0.0138025 \t0.566863\t0.686291\n",
      "23 \t71    \t0.683059\t0.0124955 \t0.584699\t0.686291\n",
      "24 \t62    \t0.682936\t0.013664  \t0.591904\t0.686291\n",
      "25 \t59    \t0.683549\t0.0128079 \t0.592809\t0.686291\n",
      "26 \t58    \t0.684197\t0.00897461\t0.622673\t0.686291\n",
      "27 \t57    \t0.681061\t0.0180614 \t0.577129\t0.686291\n",
      "28 \t77    \t0.684422\t0.00893918\t0.61548 \t0.686291\n",
      "29 \t61    \t0.684126\t0.0111247 \t0.61548 \t0.686291\n",
      "30 \t60    \t0.685279\t0.00549076\t0.645059\t0.686291\n",
      "31 \t51    \t0.683923\t0.00954233\t0.613538\t0.686291\n",
      "32 \t62    \t0.683503\t0.0107405 \t0.61548 \t0.686291\n",
      "33 \t60    \t0.68452 \t0.00950637\t0.61548 \t0.686291\n",
      "34 \t71    \t0.682389\t0.01518   \t0.600359\t0.686291\n",
      "35 \t70    \t0.683739\t0.0106983 \t0.61548 \t0.686291\n",
      "36 \t56    \t0.683568\t0.0118154 \t0.605101\t0.686291\n",
      "37 \t57    \t0.683179\t0.0120714 \t0.61548 \t0.686291\n",
      "38 \t55    \t0.683908\t0.00991361\t0.625077\t0.686291\n",
      "39 \t61    \t0.684324\t0.00850306\t0.61548 \t0.686291\n",
      "40 \t67    \t0.683783\t0.0124847 \t0.609939\t0.686291\n"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(n=100)\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, stats=stats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-objective Version\n",
    "It applies a multi-objective genetic algorithm that tries to maximize the performance while minimizing the number of features involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateFeatureSubsetMultipleObjective(individual):\n",
    "    '''returns the average performance and the number of features involved'''\n",
    "    selected_columns = []\n",
    "    for i, allele in enumerate(individual):\n",
    "        if (allele==1):\n",
    "            selected_columns.append(df.columns[i])\n",
    "\n",
    "    if (len(selected_columns)>0):\n",
    "        model = linear_model.LinearRegression()\n",
    "        scores = cross_val_score(model, df[selected_columns], y, cv=kfolds)\n",
    "        return scores.mean(), sum(individual)/float(len(individual))\n",
    "    else:\n",
    "        return 0, len(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlucalanzi/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, number_of_variables)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Operator registering\n",
    "toolbox.register(\"evaluate\", EvaluateFeatureSubsetMultipleObjective)\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.1)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selNSGA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg                    \tstd                    \tmin                    \tmax                    \n",
      "0  \t100   \t[0.50505749 0.48846154]\t[0.13286397 0.15088496]\t[0.09478814 0.07692308]\t[0.67404805 0.84615385]\n",
      "1  \t200   \t[0.54088189 0.45692308]\t[0.15574829 0.21033082]\t[0.09478814 0.07692308]\t[0.6778203  0.84615385]\n",
      "2  \t200   \t[0.5087206  0.36307692]\t[0.18927323 0.2148565 ]\t[0.09478814 0.07692308]\t[0.6778203  0.84615385]\n",
      "3  \t200   \t[0.45315159 0.32615385]\t[0.23729778 0.24132769]\t[0.09478814 0.07692308]\t[0.6778203  0.84615385]\n",
      "4  \t200   \t[0.44904449 0.33923077]\t[0.25170748 0.25234873]\t[0.12079571 0.07692308]\t[0.67814381 0.92307692]\n",
      "5  \t200   \t[0.57935314 0.39307692]\t[0.14722082 0.21997714]\t[0.19748379 0.07692308]\t[0.67853904 0.92307692]\n",
      "6  \t200   \t[0.63850749 0.42      ]\t[0.07128686 0.18792545]\t[0.23742923 0.07692308]\t[0.68201157 1.        ]\n",
      "7  \t200   \t[0.64021341 0.39      ]\t[0.04919693 0.22669611]\t[0.41057253 0.07692308]\t[0.68201157 1.        ]\n",
      "8  \t200   \t[0.65072675 0.39923077]\t[0.03032549 0.21085765]\t[0.4993403  0.07692308]\t[0.68201157 1.        ]\n",
      "9  \t200   \t[0.63567643 0.29076923]\t[0.03297942 0.18923077]\t[0.4993403  0.07692308]\t[0.68201157 1.        ]\n",
      "10 \t200   \t[0.62497806 0.28384615]\t[0.04599222 0.21029565]\t[0.4993403  0.07692308]\t[0.68201157 1.        ]\n",
      "11 \t200   \t[0.59264237 0.21923077]\t[0.06078925 0.17587482]\t[0.4993403  0.07692308]\t[0.68331854 0.92307692]\n",
      "12 \t200   \t[0.54071796 0.18461538]\t[0.06944235 0.22610675]\t[0.4993403  0.07692308]\t[0.68331854 0.92307692]\n",
      "13 \t200   \t[0.53168536 0.16153846]\t[0.06591655 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "14 \t200   \t[0.53168536 0.16153846]\t[0.06591655 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "15 \t200   \t[0.53168536 0.16153846]\t[0.06591655 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "16 \t200   \t[0.53168536 0.16153846]\t[0.06591655 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "17 \t200   \t[0.53168536 0.16153846]\t[0.06591655 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "18 \t200   \t[0.52985734 0.15461538]\t[0.06423191 0.18636828]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "19 \t200   \t[0.52992859 0.15615385]\t[0.06439706 0.19074907]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "20 \t200   \t[0.52992859 0.15615385]\t[0.06439706 0.19074907]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "21 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "22 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "23 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "24 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "25 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "26 \t200   \t[0.53171385 0.16153846]\t[0.06597949 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "27 \t200   \t[0.52988812 0.15461538]\t[0.06430276 0.18636828]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "28 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "29 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "30 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "31 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "32 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "33 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "34 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "35 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "36 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "37 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "38 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "39 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "40 \t200   \t[0.53172087 0.16153846]\t[0.06599553 0.19596522]\t[0.4993403  0.07692308]\t[0.68629149 0.84615385]\n",
      "BEST [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# random.seed(64)\n",
    "MU, LAMBDA = 100, 200\n",
    "pop = toolbox.population(n=MU)\n",
    "hof = tools.ParetoFront()\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean, axis=0)\n",
    "stats.register(\"std\", np.std, axis=0)\n",
    "stats.register(\"min\", np.min, axis=0)\n",
    "stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "pop, logbook = algorithms.eaMuPlusLambda(pop, toolbox, mu=MU, lambda_=LAMBDA,\n",
    "                                         cxpb=0.7, mutpb=0.3, ngen=40, \n",
    "                                         stats=stats, halloffame=hof)\n",
    "\n",
    "print(\"BEST \"+str(hof[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Note that we applied genetic algorithms using the entire dataset for the evaluation of the feature subset. In a real scenario we should have initially split the data as train and test and then applied the genetic algorithm only using the training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
