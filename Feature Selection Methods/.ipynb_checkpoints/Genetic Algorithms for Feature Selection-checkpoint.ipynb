{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms for Feature Selection\n",
    "This notebook shows an example of wrapper feature selection. It applies a genetic algorithm to extract a subset of features with the highest fitness. We compute the fitness using a ten-fold crossvalidation.\n",
    "\n",
    "First, we import all the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]\n",
    "zeros = np.zeros(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we compute the baseline with all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68195790533123546"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolds = KFold(10,shuffle=True,random_state=1234)\n",
    "model = linear_model.LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=kfolds)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithms\n",
    "We now import the libraries for genetic algorithms. We use the DEAP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator \n",
    "#                      define 'attr_bool' to be an attribute ('gene')\n",
    "#                      which corresponds to integers sampled uniformly\n",
    "#                      from the range [0,1] (i.e. 0 or 1 with equal\n",
    "#                      probability)\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# Structure initializers\n",
    "#                         define 'individual' to be an individual\n",
    "#                         consisting of 100 'attr_bool' elements ('genes')\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, X.shape[1])\n",
    "\n",
    "# define the population to be a list of individuals\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define fitness as the performance of linear regression using a 10-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRegressor(individual):\n",
    "    selection_mask = individual>zeros\n",
    "    scores = cross_val_score(model, X[:,selection_mask], y, cv=kfolds)\n",
    "    return scores.mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------\n",
    "# Operator registration\n",
    "#----------\n",
    "# register the goal / fitness function\n",
    "toolbox.register(\"evaluate\", evalRegressor)\n",
    "\n",
    "# register the crossover operator\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\n",
    "# register a mutation operator with a probability to\n",
    "# flip each attribute/gene of 0.05\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "# operator for selecting individuals for breeding the next\n",
    "# generation: each individual of the current generation\n",
    "# is replaced by the 'fittest' (best) of three individuals\n",
    "# drawn randomly from the current generation.\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Version of Genetic Algorithm\n",
    "First we define a basic genetic algorithm and explicitly implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_feature_selection(n=100,ngen=10):\n",
    "    random.seed(64)\n",
    "\n",
    "    # create an initial population of 300 individuals (where\n",
    "    # each individual is a list of integers)\n",
    "    pop = toolbox.population(n=300)\n",
    "\n",
    "    # CXPB  is the probability with which two individuals\n",
    "    #       are crossed\n",
    "    #\n",
    "    # MUTPB is the probability for mutating an individual\n",
    "    CXPB, MUTPB = 0.5, 0.2\n",
    "    \n",
    "    print(\"Start of evolution\")\n",
    "    \n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    print(\"  Evaluated %i individuals\" % len(pop))\n",
    "\n",
    "    # Extracting all the fitnesses of \n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    # Variable keeping track of the number of generations\n",
    "    g = 0\n",
    "    \n",
    "    # Begin the evolution\n",
    "    while max(fits) < 100 and g < ngen:\n",
    "        # A new generation\n",
    "        g = g + 1\n",
    "        print(\"-- Generation %i --\" % g)\n",
    "        \n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        # Clone the selected individuals\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "    \n",
    "        # Apply crossover and mutation on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "\n",
    "            # cross two individuals with probability CXPB\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1, child2)\n",
    "\n",
    "                # fitness values of the children\n",
    "                # must be recalculated later\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            # mutate an individual with probability MUTPB\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "    \n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        print(\"  Evaluated %i individuals\" % len(invalid_ind))\n",
    "        \n",
    "        # The population is entirely replaced by the offspring\n",
    "        pop[:] = offspring\n",
    "        \n",
    "        # Gather all the fitnesses in one list and print the stats\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "        \n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "        \n",
    "        print(\"  Min %6.4f\\tMax %6.4f\\tAvg %6.4f\\tStd %6.4f\" % (min(fits),max(fits),mean,std))\n",
    "    \n",
    "    print(\"-- End of (successful) evolution --\")\n",
    "    \n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "    \n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of evolution\n",
      "  Evaluated 300 individuals\n",
      "-- Generation 1 --\n",
      "  Evaluated 181 individuals\n",
      "  Min 0.0349\tMax 0.6862\tAvg 0.6045\tStd 0.0592\n",
      "-- Generation 2 --\n",
      "  Evaluated 203 individuals\n",
      "  Min 0.5147\tMax 0.6862\tAvg 0.6369\tStd 0.0275\n",
      "-- Generation 3 --\n",
      "  Evaluated 176 individuals\n",
      "  Min 0.5430\tMax 0.6850\tAvg 0.6555\tStd 0.0185\n",
      "-- Generation 4 --\n",
      "  Evaluated 191 individuals\n",
      "  Min 0.5973\tMax 0.6850\tAvg 0.6665\tStd 0.0129\n",
      "-- Generation 5 --\n",
      "  Evaluated 175 individuals\n",
      "  Min 0.5412\tMax 0.6862\tAvg 0.6729\tStd 0.0141\n",
      "-- Generation 6 --\n",
      "  Evaluated 170 individuals\n",
      "  Min 0.5890\tMax 0.6862\tAvg 0.6777\tStd 0.0114\n",
      "-- Generation 7 --\n",
      "  Evaluated 186 individuals\n",
      "  Min 0.5998\tMax 0.6862\tAvg 0.6799\tStd 0.0101\n",
      "-- Generation 8 --\n",
      "  Evaluated 207 individuals\n",
      "  Min 0.6251\tMax 0.6862\tAvg 0.6828\tStd 0.0059\n",
      "-- Generation 9 --\n",
      "  Evaluated 198 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6828\tStd 0.0168\n",
      "-- Generation 10 --\n",
      "  Evaluated 179 individuals\n",
      "  Min 0.5928\tMax 0.6862\tAvg 0.6836\tStd 0.0110\n",
      "-- Generation 11 --\n",
      "  Evaluated 177 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6850\tStd 0.0069\n",
      "-- Generation 12 --\n",
      "  Evaluated 196 individuals\n",
      "  Min 0.6023\tMax 0.6862\tAvg 0.6839\tStd 0.0095\n",
      "-- Generation 13 --\n",
      "  Evaluated 186 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6834\tStd 0.0112\n",
      "-- Generation 14 --\n",
      "  Evaluated 171 individuals\n",
      "  Min 0.5869\tMax 0.6862\tAvg 0.6843\tStd 0.0102\n",
      "-- Generation 15 --\n",
      "  Evaluated 183 individuals\n",
      "  Min 0.5932\tMax 0.6862\tAvg 0.6839\tStd 0.0098\n",
      "-- Generation 16 --\n",
      "  Evaluated 188 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6849\tStd 0.0071\n",
      "-- Generation 17 --\n",
      "  Evaluated 197 individuals\n",
      "  Min 0.5733\tMax 0.6862\tAvg 0.6824\tStd 0.0145\n",
      "-- Generation 18 --\n",
      "  Evaluated 172 individuals\n",
      "  Min 0.5869\tMax 0.6862\tAvg 0.6844\tStd 0.0088\n",
      "-- Generation 19 --\n",
      "  Evaluated 180 individuals\n",
      "  Min 0.6049\tMax 0.6862\tAvg 0.6850\tStd 0.0074\n",
      "-- Generation 20 --\n",
      "  Evaluated 183 individuals\n",
      "  Min 0.5869\tMax 0.6862\tAvg 0.6836\tStd 0.0116\n",
      "-- Generation 21 --\n",
      "  Evaluated 185 individuals\n",
      "  Min 0.5928\tMax 0.6862\tAvg 0.6834\tStd 0.0120\n",
      "-- Generation 22 --\n",
      "  Evaluated 196 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6828\tStd 0.0175\n",
      "-- Generation 23 --\n",
      "  Evaluated 174 individuals\n",
      "  Min 0.6133\tMax 0.6862\tAvg 0.6850\tStd 0.0066\n",
      "-- Generation 24 --\n",
      "  Evaluated 178 individuals\n",
      "  Min 0.5917\tMax 0.6862\tAvg 0.6831\tStd 0.0124\n",
      "-- Generation 25 --\n",
      "  Evaluated 168 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6839\tStd 0.0158\n",
      "-- Generation 26 --\n",
      "  Evaluated 183 individuals\n",
      "  Min 0.5998\tMax 0.6862\tAvg 0.6837\tStd 0.0103\n",
      "-- Generation 27 --\n",
      "  Evaluated 178 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6839\tStd 0.0100\n",
      "-- Generation 28 --\n",
      "  Evaluated 192 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6844\tStd 0.0085\n",
      "-- Generation 29 --\n",
      "  Evaluated 183 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6833\tStd 0.0168\n",
      "-- Generation 30 --\n",
      "  Evaluated 176 individuals\n",
      "  Min 0.5891\tMax 0.6862\tAvg 0.6843\tStd 0.0094\n",
      "-- Generation 31 --\n",
      "  Evaluated 192 individuals\n",
      "  Min 0.5869\tMax 0.6862\tAvg 0.6838\tStd 0.0107\n",
      "-- Generation 32 --\n",
      "  Evaluated 172 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6830\tStd 0.0174\n",
      "-- Generation 33 --\n",
      "  Evaluated 189 individuals\n",
      "  Min 0.4207\tMax 0.6862\tAvg 0.6833\tStd 0.0176\n",
      "-- Generation 34 --\n",
      "  Evaluated 183 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6845\tStd 0.0078\n",
      "-- Generation 35 --\n",
      "  Evaluated 176 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6828\tStd 0.0184\n",
      "-- Generation 36 --\n",
      "  Evaluated 166 individuals\n",
      "  Min 0.6153\tMax 0.6862\tAvg 0.6840\tStd 0.0090\n",
      "-- Generation 37 --\n",
      "  Evaluated 191 individuals\n",
      "  Min 0.6103\tMax 0.6862\tAvg 0.6840\tStd 0.0098\n",
      "-- Generation 38 --\n",
      "  Evaluated 165 individuals\n",
      "  Min 0.6226\tMax 0.6862\tAvg 0.6849\tStd 0.0067\n",
      "-- Generation 39 --\n",
      "  Evaluated 193 individuals\n",
      "  Min 0.4580\tMax 0.6862\tAvg 0.6837\tStd 0.0154\n",
      "-- Generation 40 --\n",
      "  Evaluated 187 individuals\n",
      "  Min 0.6023\tMax 0.6862\tAvg 0.6831\tStd 0.0128\n",
      "-- End of (successful) evolution --\n",
      "Best individual is [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], (0.68624732108842079,)\n"
     ]
    }
   ],
   "source": [
    "pop = wrapper_feature_selection(n=100,ngen=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Version \n",
    "This version uses the DEAP function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_feature_selection_short(n=100,ngen=10):\n",
    "    random.seed(64)\n",
    "    \n",
    "    pop = toolbox.population(n=300)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats_size = tools.Statistics(key=sum)\n",
    "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "    mstats.register(\"avg\", np.mean)\n",
    "    mstats.register(\"std\", np.std)\n",
    "    mstats.register(\"min\", np.min)\n",
    "    mstats.register(\"max\", np.max)\n",
    "    \n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=ngen, stats=mstats, halloffame=hof, verbose=True)\n",
    "    \n",
    "    return pop, log, hof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                    fitness                     \t              size             \n",
      "   \t      \t------------------------------------------------\t-------------------------------\n",
      "gen\tnevals\tavg    \tmax     \tmin     \tstd     \tavg \tmax\tmin\tstd    \n",
      "0  \t300   \t0.52182\t0.682615\t0.197072\t0.118963\t6.74\t12 \t3  \t1.70853\n",
      "1  \t181   \t0.604462\t0.686247\t0.0349341\t0.0591992\t7.5 \t12 \t1  \t1.66032\n",
      "2  \t203   \t0.636903\t0.686247\t0.514694 \t0.0274859\t7.97667\t12 \t4  \t1.54363\n",
      "3  \t176   \t0.655509\t0.684959\t0.54304  \t0.0185467\t8.48   \t12 \t4  \t1.57996\n",
      "4  \t191   \t0.666547\t0.684959\t0.597296 \t0.0128913\t9.14667\t12 \t5  \t1.28003\n",
      "5  \t175   \t0.672899\t0.686247\t0.541193 \t0.0140962\t9.74   \t13 \t5  \t1.16579\n",
      "6  \t170   \t0.677683\t0.686247\t0.589025 \t0.0114366\t10.2533\t12 \t7  \t0.888344\n",
      "7  \t186   \t0.679938\t0.686247\t0.59984  \t0.0101324\t10.4767\t12 \t8  \t0.877186\n",
      "8  \t207   \t0.682774\t0.686247\t0.625117 \t0.00594181\t10.7733\t13 \t8  \t0.86523 \n",
      "9  \t198   \t0.682793\t0.686247\t0.457982 \t0.0168078 \t11.0733\t13 \t9  \t0.654183\n",
      "10 \t179   \t0.683647\t0.686247\t0.59279  \t0.0110462 \t10.9833\t12 \t9  \t0.479293\n",
      "11 \t177   \t0.684983\t0.686247\t0.615279 \t0.00693594\t10.97  \t12 \t9  \t0.320052\n",
      "12 \t196   \t0.68388 \t0.686247\t0.602318 \t0.00947193\t10.89  \t12 \t8  \t0.429612\n",
      "13 \t186   \t0.68335 \t0.686247\t0.615279 \t0.0111802 \t10.9   \t12 \t9  \t0.369685\n",
      "14 \t171   \t0.684295\t0.686247\t0.586888 \t0.0101648 \t10.93  \t12 \t9  \t0.324191\n",
      "15 \t183   \t0.683862\t0.686247\t0.593218 \t0.00984906\t10.9233\t12 \t9  \t0.40512 \n",
      "16 \t188   \t0.684944\t0.686247\t0.615279 \t0.00710104\t10.9367\t12 \t9  \t0.315154\n",
      "17 \t197   \t0.682384\t0.686247\t0.573337 \t0.0145413 \t10.87  \t12 \t8  \t0.461628\n",
      "18 \t172   \t0.684415\t0.686247\t0.586888 \t0.00877206\t10.93  \t12 \t9  \t0.324191\n",
      "19 \t180   \t0.684975\t0.686247\t0.604941 \t0.00738108\t10.9467\t11 \t9  \t0.265497\n",
      "20 \t183   \t0.683602\t0.686247\t0.586888 \t0.0116141 \t10.91  \t12 \t8  \t0.393997\n",
      "21 \t185   \t0.683355\t0.686247\t0.59279  \t0.0120231 \t10.89  \t12 \t9  \t0.437302\n",
      "22 \t196   \t0.68276 \t0.686247\t0.457982 \t0.0174791 \t10.9   \t12 \t8  \t0.43589 \n",
      "23 \t174   \t0.685006\t0.686247\t0.613329 \t0.00657735\t10.9433\t12 \t9  \t0.305705\n",
      "24 \t178   \t0.68312 \t0.686247\t0.591679 \t0.0124232 \t10.88  \t12 \t8  \t0.438482\n",
      "25 \t168   \t0.683926\t0.686247\t0.457982 \t0.0157874 \t10.9133\t12 \t8  \t0.407213\n",
      "26 \t183   \t0.683674\t0.686247\t0.59984  \t0.0102783 \t10.8833\t11 \t9  \t0.38694 \n",
      "27 \t178   \t0.683853\t0.686247\t0.615279 \t0.0100434 \t10.8767\t12 \t8  \t0.463453\n",
      "28 \t192   \t0.684384\t0.686247\t0.615279 \t0.00847839\t10.91  \t12 \t8  \t0.393997\n",
      "29 \t183   \t0.683311\t0.686247\t0.457982 \t0.0167768 \t10.8967\t12 \t7  \t0.423465\n",
      "30 \t176   \t0.684329\t0.686247\t0.589082 \t0.00943205\t10.9267\t12 \t8  \t0.348266\n",
      "31 \t192   \t0.683817\t0.686247\t0.586888 \t0.0107359 \t10.9167\t12 \t9  \t0.350793\n",
      "32 \t172   \t0.683005\t0.686247\t0.457982 \t0.017429  \t10.9167\t13 \t9  \t0.369309\n",
      "33 \t189   \t0.683289\t0.686247\t0.42071  \t0.0176377 \t10.91  \t12 \t8  \t0.418609\n",
      "34 \t183   \t0.684498\t0.686247\t0.615279 \t0.00777196\t10.89  \t12 \t8  \t0.397366\n",
      "35 \t176   \t0.682813\t0.686247\t0.457982 \t0.018366  \t10.8867\t12 \t7  \t0.503808\n",
      "36 \t166   \t0.684023\t0.686247\t0.615279 \t0.00903263\t10.9033\t12 \t9  \t0.383826\n",
      "37 \t191   \t0.683972\t0.686247\t0.610311 \t0.00984835\t10.9   \t12 \t9  \t0.420317\n",
      "38 \t165   \t0.684938\t0.686247\t0.622614 \t0.00667002\t10.92  \t12 \t8  \t0.365513\n",
      "39 \t193   \t0.683721\t0.686247\t0.457982 \t0.0154436 \t10.9267\t12 \t9  \t0.348266\n",
      "40 \t187   \t0.683086\t0.686247\t0.602318 \t0.0128009 \t10.8967\t12 \t9  \t0.390712\n"
     ]
    }
   ],
   "source": [
    "pop, log, hof = wrapper_feature_selection_short(100,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Subset\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\t11\t0.686\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Feature Subset\")\n",
    "for i in range(len(hof)):\n",
    "    print('%s\\t%d\\t%.3f'%(hof[i],sum(hof[i]),hof[i].fitness.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiobjective Genetic Algorithm\n",
    "Finally, we apply a multi-objective genetic algorithm which aims at maximizing the performance and minimizing the number of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRegressorMO(individual):\n",
    "    selection_mask = individual>zeros\n",
    "    scores = cross_val_score(model, X[:,selection_mask], y, cv=kfolds)\n",
    "    return scores.mean(),len(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureSelectionMO(n=100,ngen=1):\n",
    "    creator.create(\"FitnessMultiMO\", base.Fitness, weights=(1.0, -1.0))\n",
    "    creator.create(\"IndividualMO\", list, fitness=creator.FitnessMultiMO)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"bit\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.IndividualMO, toolbox.bit, n=X.shape[1])\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, n=n)\n",
    "    toolbox.register(\"evaluate\", evalRegressorMO)\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.1)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "    hof = tools.ParetoFront()\n",
    "    population = toolbox.population()\n",
    "    fits = toolbox.map(toolbox.evaluate, population)\n",
    "    for fit, ind in zip(fits, population):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    \n",
    "\n",
    "    for gen in range(ngen):\n",
    "        offspring = algorithms.varOr(population, toolbox, lambda_=100, cxpb=0.5,mutpb=0.1)\n",
    "        offspring = [x for x in offspring if len(x)>0]\n",
    "        fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "        for fit, ind in zip(fits, offspring):\n",
    "            ind.fitness.values = fit\n",
    "        population = toolbox.select(offspring + population, k=100)\n",
    "        \n",
    "        hof.update(population)\n",
    "        \n",
    "        f1 = [x.fitness.values[0] for x in population]\n",
    "        f2 = [x.fitness.values[1] for x in population]\n",
    "    \n",
    "    return population, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "population, hof = FeatureSelectionMO(n=50,ngen=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
